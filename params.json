{"name":"Accumulo.jl","tagline":"Apache Accumulo client.","body":"# Accumulo.jl\r\n\r\n[Apache Accumulo](https://accumulo.apache.org/) is a database based on Googleâ€™s BigTable\r\n\r\nAccumulo.jl is a client library for Apache Accumulo, built using the Accumulo Thrift Proxy API.\r\n\r\n[![Build Status](https://travis-ci.org/JuliaDB/Accumulo.jl.svg?branch=master)](https://travis-ci.org/JuliaDB/Accumulo.jl)\r\n\r\n## Connecting\r\n\r\nTo connect to the server, create an instance of AccumuloSession.\r\n\r\n````\r\nsession = AccumuloSession()\r\n````\r\n\r\nWithout any parameters, this attempts to connect to a server running on `localhost` port `42424`.\r\nA remote server can be connected to by specifying the hostname and port number.\r\n\r\n````\r\nsession = AccumuloSession(\"localhost\", 42424)\r\n````\r\n\r\nAs of now only SASL-Plain authentication is supported, without any `qop`. The default implementation\r\nauthenticates with the same user-id as that of the login shell. That can be overridden by providing\r\nan appropriate instance of `AccumuloAuth`.\r\n\r\n````\r\nsession = AccumuloSession(\"localhost\", 42424, AccumuloAuthSASLPlain(\"uid\", \"pwd\", \"zid\"))\r\n````\r\n\r\nThe thrift `TCompactProtocol` is used by default, which is also the default for the server setup.\r\nOther protocols can be used by specifying the optional named parameter `tprotocol`.\r\nAs of now, `:binary` and `:compact` protocols are supported.\r\n\r\n````\r\nsession = AccumuloSession(\"localhost\", 10000; tprotocol=:compact)\r\n````\r\n\r\n## Tables\r\n\r\nAll tables in a setup can be listed with a call to `tables(session)`.\r\n\r\nExistence of a particular table can be checked with `table_exists(session, tablename)`\r\n\r\nRow/column identifiers and cell data are treated as raw bytes.\r\nAny type that can be converted to bytes can be used wherever row/column identifiers or values are expected in the APIs.\r\nSince Julia already includes this `convert` method for strings, they can be used as it is. Any other type can also get the same treatment by defining either of\r\nthe following two methods:\r\n\r\n- `convert(Vector{UInt8}, r)`\r\n- `bytes(r)`\r\n\r\n\r\n### Creating / Deleting\r\n\r\nA table can be created, deleted or renamed by calling the corresponding function passing the table name.\r\n\r\n````\r\ntable_create(session, tablename; versioning=true, logical_timestamp=false)\r\ntable_delete(session, tablename)\r\ntable_rename(session, tablename)\r\n````\r\n\r\nBy default, tables are configured to use the `VersioningIterator` and keep one version.\r\nThe version policy can be changed by changing the `VersioningIterator` options with the `table_config!` function.\r\n\r\nUsing logical timestamps ensures timestamps always move forward. Though the actual millisecond time will not be used anymore, with this, tablet servers need not \r\nbe time synchronized pefectly and multile updates at the same millisecond do not cause any issue.\r\n\r\n\r\n### Cloning\r\n\r\nA table can be cloned with:\r\n\r\n````\r\ntable_clone(session, tablename, newtablename; flush=true, \r\n            set_properties=Dict(), exclude_properties=())\r\n````\r\n\r\nIf the flush option is not enabled, then any data the source table currently has in memory will not exist in the clone.\r\nA cloned table copies the configuration of the source table. However the permissions of the source table are not copied to the clone.\r\nAfter a clone is created, only the user that created the clone can read and write to it.\r\n\r\n\r\n\r\n### Configuration\r\n\r\nTo get or set table specific properties:\r\n\r\n````\r\ntable_config(session, tablename)\r\ntable_config!(session, tablename, property::AbstractString, value::AbstractString)\r\n````\r\n\r\n`table_versions!` changes the number of versions the `VersioningIterator` keeps.\r\n\r\n`table_versions!(session, tablename, nversions::Integer)`\r\n\r\n`table_du` prints how much space, in bytes, is used by files referenced by a table. When multiple tables are specified it prints how much space, in bytes, is used by files shared between tables, if any.\r\n\r\n`table_du(session, tables::AbstractString...)`\r\n\r\n\r\n### Constraints\r\n\r\nConstraints are applied on mutations at insert time and only those that satify them are allowed.\r\nConstraints must be implemented as a Java class and included in Accumulo classpath.\r\n\r\n````\r\n# list constraints as a map of the class name and an integer ID\r\nconstraints(session, tablename)\r\n\r\n# add and remove constraints\r\nadd_constraints(session, tablename, names::AbstractString...)\r\nremove_constraints(session, tablename, ids::Integer...)\r\n````\r\n\r\n### Splits\r\n\r\nTablets constituting a table are automatically split based on a size threshold configurable per table.\r\nTablets can also be manually split or merged through the following APIs to tweak performance.\r\nSplit points are specified as row values.\r\n\r\n````\r\n# list current splits (upto max_splits)\r\ntable_splits(session, tablename, max_splits=1024)\r\n\r\n# manually split / merge tablets\r\ntable_split(session, tablename, splits...)\r\ntable_merge(session, tablename, start_split, end_split)\r\n````\r\n\r\n### Exporting / Importing \r\n\r\nTables can be moved across clusters by exporting them from the source, copying them via the hadoop `distcp` command, and importing them at the destination.\r\nExporting and importing tables preserves the tables configuration, splits, and logical time.\r\n\r\n````\r\ntable_export(session, tablename, export_dir::AbstractString)\r\ntable_import(session, tablename, import_dir::AbstractString)\r\n````\r\n\r\nTable must be kept offline during an export while discp runs (to prevent files from being deleted).\r\nA table can be cloned and the clone taken offline to be able to access the table during an export.\r\n\r\n````\r\ntable_offline(session, tablename; wait=true)\r\ntable_online(session, tablename; wait=true)\r\n````\r\n\r\n## Iterators\r\n\r\nIterators are executed by Accumulo while scanning or compacting tables. They are a way of doing distributed operations on tables.\r\nIterators must be implemented as a Java class and included in Accumulo classpath.\r\nThey can be configured to be used during scanning or compaction events. The `IteratorScope` enum lists allowed scopes.\r\n\r\n````\r\n# list all iterators as a dict of class name and the scopes registered\r\niters(session, tablename)\r\n\r\n# retrieve a single matching iterator with its setting\r\niter(session, tablename, itername::AbstractString, scope::Integer)\r\n````\r\n\r\nThe below APIs allow configuring iterators for a table.\r\n\r\n````\r\n# create an iterator setting\r\niter(name, class, priority::Integer, properties::Dict=Dict())\r\n\r\n# verify whether the iterator settings will be valid when applied on a table\r\ncheck_iter(session, tablename, iter_setting::IteratorSetting, scopes)\r\n\r\n# add or remote iterators configured on a table\r\nadd_iter(session, tablename, iter_setting::IteratorSetting, scopes; check=true)\r\nremove_iter(session, tablename, iter_setting::IteratorSetting, scopes)\r\nremove_iter(session, tablename, iter_name::AbstractString, scopes)\r\n\r\n````\r\n\r\n## Writing\r\n\r\nData is written to tables as batches of updates.\r\n\r\n````\r\n# initialize a batch\r\nupdates = batch()\r\n\r\n# add mutations to the batch\r\nupdate(updates, row, col_family, col_qualifier, col_visibility, value, timestamp::Integer=time_ms())\r\ndelete(updates, row, col_family, col_qualifier)\r\n\r\n# update table\r\nupdate(session, tablename, updates)\r\n````\r\n\r\nUpdates can also be conditional. A condition is created using `where`.\r\n\r\n````\r\n# initialize a conditional batch\r\nupdates = conditional_batch()\r\n\r\n# add a condition; comparing values, timestamps and also running additional iterators to evaluate complex conditions\r\nwhere(updates, row, col_family, col_qualifier, col_visibility; value=nothing, timestamp=-1, iterators=IteratorSetting[])\r\n\r\n# add mutations\r\nupdate(updates, row, col_family, col_qualifier, col_visibility, value, timestamp::Integer=time_ms())\r\ndelete(updates, row, col_family, col_qualifier)\r\n\r\n# update the table\r\nupdate(session, tablename, updates)\r\n````\r\n\r\nMultiple batch updates can be applied by first obtaining a table writer.\r\n\r\n````\r\nbatch_writer(session, tablename) do writer\r\n    for i in 1:10\r\n        updates = batch()\r\n        for rownum in 1:N\r\n            update(upd, \"row$rownum\", \"colf\", \"colq\", \"\", \"value$rownum\")\r\n        end\r\n        update(writer, upd)\r\n        flush(writer)\r\n    end\r\nend\r\n````\r\n\r\nAnd similarly for conditional updates:\r\n\r\n````\r\nconditional_batch_writer(session, tablename) do writer\r\n    for i in 1:10\r\n        upd = conditional_batch()\r\n        for rownum in 1:N\r\n            row = \"row$rownum\"\r\n            val = \"value$rownum\"\r\n            update(where(upd, row, \"colf\", \"colq\"; value=val), \"colf\", \"colq\", \"\", \"newvalue$rownum\")\r\n        end\r\n        update(writer, upd)\r\n        flush(writer)\r\n    end\r\nend\r\n```` \r\n\r\n## Reading\r\n\r\nData can be read from tables using a scanner and iterating over the records.\r\n\r\n````\r\n# create a scanner\r\nscanner(session, tablename) do scan\r\n    # iterate over the records\r\n    for rec in records(scan)\r\n        # each record has key and value\r\n        key = rec.key\r\n        val = rec.value\r\n\r\n        # the key consists of the row and column identifiers\r\n        row = key.row\r\n        colfam = key.colFamily\r\n        colqual = key.colQualifier\r\n        colvis = key.colVisibility\r\n\r\n        # ...\r\n    end\r\nend\r\n````\r\n\r\nOnly a subset of the columns can be fetched by specifying the list of columns as:\r\n\r\n````\r\nscanner(session, tablename; columns=[(\"colfam1\",\"colqual1\"), (\"colfam2\",\"colqual2\")])\r\n````\r\n\r\nAdditional iterators can be specified to be used with the scanner:\r\n\r\n````\r\n# iterator settings\r\niter1 = iter(name, class, priority::Integer, properties::Dict=Dict())\r\niter2 = iter(name, class, priority::Integer, properties::Dict=Dict())\r\n\r\n# specify additional iterators to be used\r\nscanner(session, tablename; iterators=[iter1, iter2])\r\n````\r\n\r\nThe scanner can be restricted to only a single row or a subset of matching rows by specifying a range of keys to iterate over.\r\n\r\n````\r\n# assign appropriate key or range of keys to rng\r\nscanner(session, tablename; rng=:())\r\n````\r\n\r\nA scanner key can be created using:\r\n\r\n````\r\nscanner_key(row; col_family=\"\", col_qualifier=\"\", col_visibility=\"\", timestamp=0x7FFFFFFFFFFFFFFF)\r\n````\r\n\r\nA range of keys can be specified as expressions of the form `k1 <= x < k2` where:\r\n- `k1` and `k2` are the bounds. They can either be just the row value, or a key created using `scanner_key`\r\n- `<=`, `<`, `>`, `>=` help specify the lower and upper bounds and their inclusivity\r\n- `x` is just any symbol to complete the expression syntax\r\n\r\nThe range bounds (`k1` and `k2` above) can be one of the following:\r\n- just the row (bytes or type that can be converted to bytes)\r\n- a key created by `scanner_key`\r\n- an expression that evaluates to one of the above\r\n\r\n\r\n## TODO:\r\n\r\n- suppport for\r\n    - table compactions\r\n    - locality groups\r\n    - namespaces\r\n- additional authentication methods\r\n- nicer API\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}